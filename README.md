# MetaClaw ğŸ¾

![Version](https://img.shields.io/badge/version-3.0.0-blue)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Personal AI assistant running on Telegram via GramJS (MTProto).

## Features

### Core
- ğŸ¤– **Smart AI Chat** â€” GPT-5.2 (simple) + Claude Opus 4.6 (complex) with auto-routing
- ğŸ§­ **AI-Powered Routing** â€” Gemini Flash intent classifier for smart model selection
- ğŸ“¬ **Message Batching** â€” DM=5s, Group=30s per user, typing detection resets timer
- ğŸ”§ **Native Function Calling** â€” Shell, web search, file R/W via provider-native tool APIs
- ğŸ§  **Memory + RAG** â€” Auto-memory, semantic search, knowledge base with embeddings
- ğŸ’¬ **Conversation Persistence** â€” History with embedding-based relevance filtering & auto-compaction
- ğŸ“¨ **Message Queue** â€” Rate-limited sending with flood wait protection (no Telegram bans)

### Native Tools (17 Built-in)

| Category | Tools |
|----------|-------|
| **Execution** | `shell`, `async_shell` |
| **Web** | `search`, `fetch` |
| **Files** | `read`, `write`, `ls` |
| **Media** | `image` |
| **Scheduling** | `schedule` |
| **Agents** | `spawn_subagent`, `active_tasks` |
| **Knowledge** | `knowledge`, `remember` |
| **Communication** | `send_file`, `send_voice`, `send_sticker` |
| **Planning** | `task_plan` |

### Anti-Duplicate System
Multi-layered protection against runaway task loops:

- **System prompt awareness** â€” AI always sees active tasks, warned not to duplicate
- **`active_tasks` tool** â€” Check running tasks/agents/schedules before spawning
- **Spawn dedup** â€” Fuzzy goal matching blocks similar sub-agents (>50% word overlap)
- **Schedule dedup** â€” Same message + within 5 min window = blocked
- **AsyncTask dedup** â€” Same command running = returns existing ID
- **AsyncTask cooldown** â€” Same command completed <60s ago = skipped
- **Max concurrent** â€” Max 3 async tasks simultaneously
- **Isolated context restrictions** â€” No schedule/spawn tools in background processing
- **Emergency commands** â€” `/stoptasks`, `/stopagents`, `/stopall`, `/clearall`

### Sub-Agents
- ğŸ¤– **Autonomous AI Workers** â€” Spawn background agents with plan & execute phases
- ğŸ“‹ **Dual-Model Architecture** â€” GPT-5.2 (planning, reasoning: high) + MiniMax M2.5 (execution)
- â±ï¸ **Configurable Turns** â€” Max 100 turns per task (configurable)
- ğŸ”„ **Auto-Retry** â€” 3 retries with 10-30s exponential backoff
- ğŸ“Š **Progress Reporting** â€” Status updates every 5 turns
- ğŸ’¬ **Communication** â€” Progress reports, mid-task clarification, abort support
- ğŸ”— **Task Chaining** â€” Output of task A feeds into task B

### Session Management
- ğŸ“‘ **Isolated Sessions** â€” Multiple conversation contexts per chat
- ğŸ”€ **Session Switching** â€” Switch between active sessions
- ğŸŒ¿ **Session Branching** â€” Fork with embedding-based context transfer
- ğŸ¤– **AI Compaction** â€” Smart summarization when sessions get long

### Skills (Plugin System)
- ğŸ”Œ **Code-Driven Skills** â€” Register as native function calling tools
- ğŸ¯ **Trigger-Based Loading** â€” Auto-load on matching user queries
- ğŸ“¦ **Install from Git/Local** â€” `installSkill()` from any source
- ğŸ”„ **Hot Reload** â€” Load/unload/reload without restart

### Monitoring
- â¤ï¸ **Heartbeat System** â€” Periodic checks via HEARTBEAT.md (hot-reloadable)
- ğŸ’° **Zero-Token Monitoring** â€” Shell checks first, AI only when conditions trigger
- â° **Smart Scheduler** â€” 3-tier (direct/check/agent) with conditional triggers

### Infrastructure
- ğŸ–¥ï¸ **Multi-Instance Communication** â€” Redis pub/sub, delegate_task between instances
- ğŸ“¨ **Message Queue** â€” Global rate limiting (1.5s), per-chat throttling (3s), flood wait handling
- ğŸ›¡ï¸ **Access Control** â€” Whitelist, auto-reject calls, auto-leave unauthorized groups
- ğŸ“Š **Stats & Cost Tracking** â€” Per-model cost estimates
- ğŸ”„ **Model Fallback** â€” Auto-switch provider on failure

## Requirements
- **OS:** Linux (Ubuntu 22.04+ recommended)
- **Node.js:** v18+
- **npm:** v9+

## Quick Start

```bash
# 1. Clone & install
git clone https://github.com/metasanjaya/metaclaw
cd metaclaw
npm run install-all

# 2. Run the setup wizard
npm run setup

# 3. First-time login (interactive)
node src/gramjs/index.js
# â†’ Enter phone, code, 2FA â†’ wait for "listening" â†’ Ctrl+C

# 4. Start with pm2
pm2 start src/gramjs/index.js --name metaclaw
pm2 save && pm2 startup
```

## Default Model Configuration

```yaml
models:
  # Simple tasks (casual chat, quick answers)
  simple:
    provider: openai
    model: gpt-5.2
    reasoning: medium

  # Complex tasks (analysis, debugging, multi-step)
  complex:
    provider: anthropic
    model: claude-opus-4-6

  # Intent classification & vision
  intent:
    provider: google
    model: gemini-2.5-flash
  vision:
    provider: google
    model: gemini-2.5-flash

  # Fallback
  fallback:
    provider: google
    model: gemini-3

# Sub-Agent models
subagent:
  planner:
    provider: openai
    model: gpt-5.2
    reasoning: high
  executor:
    provider: minimax
    model: MiniMax-M2.5
```

## Commands

| Command | Description |
|---------|-------------|
| `/stats` | Usage statistics |
| `/dailyusage` | Daily stats with cost estimate |
| `/clear` | Delete messages & reset conversation |
| `/remember <text>` | Save to memory |
| `/memory` | Show recent memories |
| `/forget` | Clear today's memory |
| `/subagent <goal>` | Spawn autonomous AI worker |
| `/subagent:status [id]` | Check task status |
| `/subagent:abort <id>` | Abort a running task |
| `/sessions` | List all sessions |
| `/skills` | List installed skills |
| `/heartbeat` | Heartbeat status |
| `/stoptasks` | Stop all async tasks |
| `/stopagents` | Abort all sub-agents |
| `/stopall` | Stop all tasks + agents |
| `/clearall` | Stop + delete all tasks & agents |

## HEARTBEAT.md

```markdown
## interval: 300
## notify: <telegram_user_id>

## Checks
- disk: `df -h / | awk 'NR==2{print $5}' | tr -d %` | if >85 | Disk usage high
- mem: `free -m | awk '/Mem/{printf "%.0f", $3/$2*100}'` | if >90 | Memory high

## Tasks
- email: Check inbox for urgent emails | every 4h
```

## Architecture

```
src/gramjs/
â”œâ”€â”€ GramJSBridge.js        # Main orchestrator
â”œâ”€â”€ GramJSClient.js        # MTProto connection
â”œâ”€â”€ MessageQueue.js        # Rate-limited message sending
â”œâ”€â”€ SubAgent.js            # Autonomous AI workers
â”œâ”€â”€ AsyncTaskManager.js    # Background shell tasks (dedup + rate limit)
â”œâ”€â”€ Scheduler.js           # Persistent job scheduler (dedup)
â”œâ”€â”€ SessionManager.js      # Structured session contexts
â”œâ”€â”€ SkillManager.js        # Plugin system
â”œâ”€â”€ HeartbeatManager.js    # Periodic monitoring
â”œâ”€â”€ ConversationManager.js # Chat history + embeddings
â”œâ”€â”€ KnowledgeManager.js    # Dynamic knowledge base
â”œâ”€â”€ MemoryManager.js       # Memory system
â”œâ”€â”€ RAGEngine.js           # Retrieval-augmented generation
â”œâ”€â”€ InstanceManager.js     # Multi-instance communication
â”œâ”€â”€ StatsTracker.js        # Usage statistics
â””â”€â”€ ChatQueue.js           # Concurrent chat processing

src/ai/
â”œâ”€â”€ UnifiedAIClient.js     # Multi-provider AI client
â””â”€â”€ providers/             # Anthropic, Google, OpenAI, MiniMax
```

## Providers

- **Kimi (Moonshot)** â€” K2.5 (OpenAI-compatible)
- **Anthropic** â€” Claude Opus 4.6, Sonnet 4.5
- **Google** â€” Gemini Flash/Pro/3
- **OpenAI** â€” GPT-5.2, Codex (Responses API)
- **MiniMax** â€” M2.5
- **DeepSeek** â€” DeepSeek Chat
- **Grok (xAI)** â€” Grok-2
- **Z.AI** â€” GLM-5

## Configuration

### Per-Model Temperature
```yaml
models:
  simple:
    provider: kimi
    model: kimi-k2.5
    temperature: 1    # Kimi only accepts 1
```

### Response Delay
```yaml
response_delay:
  dm: 3       # seconds before replying in DM
  group: 5    # seconds before replying in group
```

### Config Validation
Startup validates `config.yaml` against schema (Zod). Invalid configs fail fast with clear error messages.

## License
MIT

---
**MetaClaw** â€” Built by Meta Sanjaya ğŸ¾
