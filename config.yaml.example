# MetaClaw Configuration
# Generated by setup wizard or edit manually

# Telegram connection
gramjs:
  api_id: ${TELEGRAM_API_ID}
  api_hash: ${TELEGRAM_API_HASH}
  session_file: data/session.txt
  whitelist: []
  group_mode: mention_only  # mention_only | all

# Smart Model Routing
models:
  # Simple tasks (casual chat, quick answers)
  simple:
    provider: kimi
    model: kimi-k2.5
    reasoning: high
    temperature: 1

  # Complex tasks (analysis, debugging, multi-step)
  complex:
    provider: kimi
    model: kimi-k2.5
    reasoning: high
    temperature: 1

  # Intent classification & vision
  intent:
    provider: google
    model: gemini-2.5-flash
    temperature: 0
  vision:
    provider: google
    model: gemini-2.5-flash
    temperature: 0

  # Fallback when primary fails
  fallback:
    provider: google
    model: gemini-3
    temperature: 0.7

# Response delay (seconds before sending reply)
response_delay:
  dm: 3       # delay for DM messages
  group: 5    # delay for group messages

# Sub-Agent Models
subagent:
  planner:
    provider: openai
    model: gpt-5.2
    reasoning: high
  executor:
    provider: kimi
    model: kimi-k2.5

# Access Control
access_control:
  reject_calls: true
  auto_leave_unauthorized: true

# Tools
tools:
  max_rounds: 100  # max tool call rounds per message

# Debug mode (dumps AI requests to data/debug/)
debug: false

# Workspace (MetaClaw's working directory)
workspace:
  path: ./workspace

# Features
features:
  streaming: false  # placeholder + edit response mode

# Remote LLM Providers (API keys)
# llm:
#   remote:
#     providers:
#       kimi:
#         api_key: sk-your-kimi-key
#       minimax:
#         api_key: sk-your-minimax-key
#         base_url: https://api.minimax.io/anthropic

# Multi-instance communication (optional)
# instance:
#   id: my-instance
#   name: "My Instance"
#   scope: "General assistant"
#   redis:
#     url: redis://localhost:6379
#     prefix: metaclaw
